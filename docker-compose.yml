version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: cs720-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: cs720
      POSTGRES_PASSWORD: cs720_dev_password
      POSTGRES_DB: cs720
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cs720"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend Service
  backend:
    image: ghcr.io/script-repo/cs720-backend:latest
    container_name: cs720-backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3001
      DATABASE_URL: postgresql://cs720:cs720_dev_password@postgres:5432/cs720
      JWT_SECRET: your-secret-key-change-in-production
    ports:
      - "3001:3001"
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      start_period: 20s
      retries: 3

  # CORS Proxy Service
  proxy:
    image: ghcr.io/script-repo/cs720-proxy:latest
    container_name: cs720-proxy
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3002
    ports:
      - "3002:3002"
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3002/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      start_period: 20s
      retries: 3

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: cs720-ollama
    restart: unless-stopped
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
    # Uncomment if you have GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3

  # AI Service
  ai-service:
    image: ghcr.io/script-repo/cs720-ai-service:latest
    container_name: cs720-ai-service
    restart: unless-stopped
    depends_on:
      ollama:
        condition: service_started
      proxy:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3003
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: llama2
      PROXY_URL: http://proxy:3002
      PREFERRED_BACKEND: ollama
    ports:
      - "3003:3003"
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3003/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      start_period: 20s
      retries: 3

  # Frontend Service
  frontend:
    image: ghcr.io/script-repo/cs720-frontend:latest
    container_name: cs720-frontend
    restart: unless-stopped
    depends_on:
      backend:
        condition: service_healthy
      ai-service:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3000
      NEXT_PUBLIC_API_URL: http://localhost:3001
      NEXT_PUBLIC_AI_SERVICE_URL: http://localhost:3003
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 3s
      start_period: 20s
      retries: 3

volumes:
  postgres-data:
    name: cs720-postgres-data
  ollama-data:
    name: cs720-ollama-data

networks:
  default:
    name: cs720-network
